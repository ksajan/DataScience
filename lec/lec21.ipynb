{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "np.set_printoptions(legacy='1.13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey analysis ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We asked: \"Rate your agreement with the following statement: The climate at UC Berkeley prevents some people from saying things they believe because others might find them offensive.\"  97 said \"strongly agree\" and 152 said \"somewhat agree\", out of 290 responses.  In comparison, a [2016 Gallup survey](www.knightfoundation.org/media/uploads/publication_pdfs/FreeSpeech_campus.pdf) found that, among the college population at large in the US, 54% said \"strongly agree\" or \"somewhat agree\".  Let's compare our respondents to the national population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_yes = 0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_statistic(observed_yes):\n",
    "    return abs(observed_yes - predicted_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_stat = test_statistic((97 + 152) / 290)\n",
    "observed_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_yes = sample_proportions(290, make_array(0.54, 0.46)).item(0)\n",
    "test_statistic(simulated_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_stats = make_array()\n",
    "\n",
    "for i in np.arange(10000):\n",
    "    simulated_yes = sample_proportions(290, make_array(0.54, 0.46)).item(0)\n",
    "    new_stat = test_statistic(simulated_yes)\n",
    "    simulated_stats = np.append(simulated_stats, new_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Null distribution', simulated_stats).hist()\n",
    "_ = plots.plot([observed_stat, observed_stat], [0, 1.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_pval = np.count_nonzero(simulated_stats >= observed_stat) / 10000\n",
    "empirical_pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deflategate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "football = Table.read_table('http://inferentialthinking.com/notebooks/football.csv')\n",
    "football = football.drop('Team')\n",
    "football.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initials = np.append(np.ones(11) * 12.5, np.ones(4) * 13)\n",
    "halftime_wts = (football.column('Blakeman')+football.column('Prioleau'))/2\n",
    "football = football.with_column(\n",
    "    'Team', np.char.strip(football.column('Ball'), [' 1234567890']),\n",
    "    'Weight at Halftime', halftime_wts,\n",
    "    'Estimate at Start', initials,\n",
    "    'Drop', initials - halftime_wts\n",
    ")\n",
    "football.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_average_drop(t):\n",
    "    averages = t.select('Team', 'Drop').group('Team', np.average).column(1)\n",
    "    return averages.item(1) - averages.item(0)\n",
    "\n",
    "observed = difference_in_average_drop(football)\n",
    "observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_labels = football.select('Team')\n",
    "drops = football.select('Drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_drops = drops.sample(with_replacement=False).column(0)\n",
    "shuffled_tbl = group_labels.with_column('Drop', shuffled_drops)\n",
    "difference_in_average_drop(shuffled_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_stats = make_array()\n",
    "\n",
    "for i in np.arange(10000):\n",
    "    shuffled_drops = drops.sample(with_replacement=False).column(0)\n",
    "    shuffled_tbl = group_labels.with_column('Drop', shuffled_drops)\n",
    "    new_diff = difference_in_average_drop(shuffled_tbl)\n",
    "    sampled_stats = np.append(sampled_stats, new_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Null distribution', sampled_stats).hist()\n",
    "_ = plots.plot([observed, observed], [0, 1.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(sampled_stats >= observed)/len(sampled_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Toast Myth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw the Mythbusters crew do an experiment with 48 pieces of toast, where 29 landed butter side up and 19 butter side down.  Let's see if we can figure out how likely this outcome would be, if toast was equally likely to land on either side.  In particular, we'll play a \"what-if\" game: what if toast was equally likely to land on both sides?  Let's simulate what would happen, under that assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sides = make_array('Butter Side Up', 'Butter Side Down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_outcomes = Table().with_column('Outcome', sides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_experiment = possible_outcomes.sample(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_experiment.group('Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_up(sample):\n",
    "    counts = sample.group('Outcome').where('Outcome', 'Butter Side Up')\n",
    "    number_up = counts.column('count').item(0)\n",
    "    return number_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_up(simulated_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we saw how to simulate an episode of the TV show (i.e., one experiment), under the \"what-if\" assumption that toast is equally likely to land on both sides.  Now we're going to repeat the simulation 10000 times, and keep track of the statistic (the number of times the toast landed butter-side-up) we get from each simulated TV episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = make_array()\n",
    "for i in np.arange(10000): # 10000 repetitions\n",
    "    one_simulated_episode = possible_outcomes.sample(48)\n",
    "    number_up = count_up(one_simulated_episode)\n",
    "    counts = np.append(counts, number_up)\n",
    "results = Table().with_column('Number that landed butter-side-up', counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.hist(bins=np.arange(12,36,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.where('Number that landed butter-side-up',\n",
    "              are.above_or_equal_to(29)).num_rows / 10000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
